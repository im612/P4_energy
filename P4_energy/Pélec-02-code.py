# -*- coding: utf-8 -*-
"""Copie de P4-test-performance.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QZ-QyTBp_B9Ni1MkoZ1mhA6sPlR-ng4E
"""

#!/opt/anaconda3/bin/python3.9
#Inizializzazione
import pandas as pd

# from pandas import Series, DataFrame
import numpy as np
import scipy
import sys
import matplotlib.pyplot as plt
from scipy import stats
from scipy.stats import kstest, anderson, pearsonr, kurtosis
import math
import seaborn as sns
from sklearn import preprocessing
import datetime, os

from sklearn.model_selection import KFold
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import make_scorer, mean_squared_error, r2_score
from sklearn import model_selection

from sklearn.model_selection import GridSearchCV, train_test_split
from sklearn.dummy import DummyRegressor
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import RidgeCV, Ridge
from sklearn.linear_model import LassoCV, Lasso
from sklearn.linear_model import ElasticNet, ElasticNetCV
from sklearn.ensemble import RandomForestRegressor
from sklearn.base import clone

# Écriture di stdout and stderr dans un fichier extérieur
sys.stdout = open('out.log', 'w')
sys.stderr = sys.stdout

#1. Importation des dataframes nettoyés et traités ( 2015, 2016, 2015+2016 concat, df_2015_et_2016_concat_star_clean, 2015+2016 merged)
df_15 = pd.read_csv("data/df_2015_clean.csv", sep=',')
df_16 = pd.read_csv("data/df_2016_clean.csv", sep=',')
df_15_et_16_concat = pd.read_csv("data/df_2015_et_2016_concat_clean.csv", sep=',')
df_15_et_16_concat_star = pd.read_csv("data/df_2015_et_2016_concat_star_clean.csv", sep=',')
df_15_et_16_merged = pd.read_csv("data/df_2015_et_2016_merged_clean.csv", sep=',')

# Création de la classe Feature, qui permettra de traiter les features comme des objets
#   Création de la classe feature ( 2015, 2016, 2015+2016 concat, 2015+2016 merged)
class Feature:
    # Dataframe d'origine
    def set_df(self, df):
        self.df = df

    def get_df(self):
        return self.df

    # Nom du dataframe d'origine. Utile comme etiquette.
    def set_dfname(self, dfname):
        self.dfname = dfname

    def get_dfname(self):
        return self.dfname

    # Nom de la feature associée à l'istance
    def set_name(self, name):
        self.name = name

    def get_name(self):
        return self.name

    # Nom de la feature associée à l'istance avec le df marque
    def set_fullname(self, fullname):
        self.fullname = fullname

    def get_fullname(self):
        return self.fullname

    def which_feature_am_i(self):
        inst_def='Cet instance %s est associée à la feature %s du jeu de données %s, colonne (%s)' % (self, )
        return()

    def show_beginning(self, df, feat):
        print(df[feat].head())

    def create_df_for_hist(self):
        df_for_hist_pie = self.df.groupby([self.namefeat]).count().sort_values(by=self.namefeat, ascending='True').iloc[:, 1]
        df_for_hist_pie2 = df_for_hist_pie.fillna(0)
        return df_for_hist_pie2

# Création des objets features
df_sources = [ [df_15, 'df_15'], [df_16, 'df_16'], [df_15_et_16_concat, 'df_15_et_16_concat'], [ df_15_et_16_merged, 'df_15_et_16_merged'], [ df_15_et_16_concat_star, 'df_15_et_16_concat_star'] ]

def create_features_instances(ind, feat_list):
    #le nom de l'instance est pris de feat_list
    list_of_instances = [Feature() for i in feat_list]  

    for i in list_of_instances:
        i.set_df(df_sources[ind][0])
        i.set_dfname(df_sources[ind][1])
        i.set_fullname('%s_%s' % (feat_list[list_of_instances.index(i)], df_sources[ind][1]) )
        i.set_name(feat_list[list_of_instances.index(i)])
        # print(i.get_fullname())

    return list_of_instances

list_of_feature_names_15 = ['BuildingType', 'NumberofBuildings', 'NumberofFloors', 'PropertyGFATotal', 'PropertyGFAParking', 'PropertyGFABuilding(s)', 'YearsENERGYSTARCertified', 'ENERGYSTARScore', 'SiteEnergyUse(kBtu)', 'SiteEnergyUseWN(kBtu)', 'SiteEUI(kBtu_over_sf)', 'SiteEUIWN(kBtu_over_sf)', 'TotalGHGEmissions', 'GHGEmissionsIntensity', 'Compl', 'Outlier_ok', 'Anciennete', 'measure_floors', 'log_PropertyGFABuilding(s)', 'log_measure_floors', 'log_SiteEnergyUse(kBtu)', 'log_SiteEnergyUseWN(kBtu)', 'log_SiteEUI(kBtu_over_sf)', 'log_SiteEUIWN(kBtu_over_sf)', 'log_TotalGHGEmissions', 'log_GHGEmissionsIntensity', 'log_PropertyGFATotal', 'log_PropertyGFAParking']
list_of_feature_names_16 = list_of_feature_names_15

def create_instances_for_all_series():
    list_of_instances_15 = create_features_instances(0, list_of_feature_names_15)
    list_of_instances_16 = create_features_instances(1, list_of_feature_names_16)
    list_of_instances_15_and_16 = create_features_instances(2, list_of_feature_names_16)
    # list_of_instances_15_and_16_merged = create_features_instances(3, list_of_feature_names_16)
    list_of_instances_15_and_16_star = create_features_instances(4, list_of_feature_names_16) #!!! l'indice en [0] doit etre celui de df_sources 

    return list_of_instances_15, list_of_instances_16, list_of_instances_15_and_16, list_of_instances_15_and_16_star

list_of_instances_15, list_of_instances_16, list_of_instances_15_and_16, list_of_instances_15_and_16_star = create_instances_for_all_series()

#FIN DE LA CRÉATION DES INSTANCES FEATURES
#################################
#################################
#################################
#################################

# Création des modèles
# Association du nom du dataframe et de la liste des instances
l_l_instances = [['df_15', list_of_instances_15], ['df_16', list_of_instances_16], ['df_15_et_16_concat', list_of_instances_15_and_16], ['df_15_et_16_concat_star', list_of_instances_15_and_16_star] ]

# Paramètres des modèles
modeles_lineaires9 = [[['PropertyGFATotal', 'PropertyGFAParking', 'NumberofBuildings', 'Anciennete', 'measure_floors'], 'TotalGHGEmissions', 'df_15_et_16_concat'],
                      [['PropertyGFATotal', 'PropertyGFAParking', 'PropertyGFABuilding(s)', 'NumberofBuildings', 'Anciennete'], 'TotalGHGEmissions', 'df_15_et_16_concat'],
                      [['PropertyGFATotal', 'PropertyGFAParking', 'NumberofBuildings', 'Anciennete', 'measure_floors'], 'TotalGHGEmissions', 'df_15_et_16_concat']]

modeles_lineaires10 = [[['log_PropertyGFATotal', 'log_PropertyGFAParking', 'NumberofBuildings', 'Anciennete', 'log_measure_floors'], 'log_TotalGHGEmissions', 'df_15_et_16_concat'],
                      [['log_PropertyGFATotal', 'log_PropertyGFAParking', 'log_PropertyGFABuilding(s)', 'NumberofBuildings', 'Anciennete'], 'log_TotalGHGEmissions', 'df_15_et_16_concat'],
                      [['log_PropertyGFATotal', 'log_PropertyGFAParking', 'NumberofBuildings', 'Anciennete', 'log_measure_floors'], 'log_TotalGHGEmissions', 'df_15_et_16_concat']]

modeles_lineaires11 = [[['log_PropertyGFATotal', 'log_PropertyGFAParking', 'NumberofBuildings', 'Anciennete', 'log_measure_floors'], 'SiteEnergyUse(kBtu)', 'df_15_et_16_concat'],
                      [['log_PropertyGFATotal', 'log_PropertyGFAParking', 'log_PropertyGFABuilding(s)', 'NumberofBuildings', 'Anciennete'], 'SiteEnergyUse(kBtu)', 'df_15_et_16_concat'],
                      [['log_PropertyGFATotal', 'log_PropertyGFAParking', 'NumberofBuildings', 'Anciennete', 'log_measure_floors'], 'SiteEnergyUse(kBtu)', 'df_15_et_16_concat']]


modeles_lineaires12 = [[['log_PropertyGFATotal', 'log_PropertyGFAParking', 'NumberofBuildings', 'Anciennete', 'log_measure_floors'], 'log_SiteEnergyUse(kBtu)', 'df_15_et_16_concat'],
                      [['log_PropertyGFATotal', 'log_PropertyGFAParking', 'log_PropertyGFABuilding(s)', 'NumberofBuildings', 'Anciennete'], 'log_SiteEnergyUse(kBtu)', 'df_15_et_16_concat'],
                      [['log_PropertyGFATotal', 'log_PropertyGFAParking', 'NumberofBuildings', 'Anciennete', 'log_measure_floors'], 'log_SiteEnergyUse(kBtu)', 'df_15_et_16_concat']]

modeles_lineaires12b = [[['log_PropertyGFATotal', 'log_PropertyGFAParking', 'NumberofBuildings', 'Anciennete', 'log_measure_floors'], 'SiteEnergyUse(kBtu)', 'df_15_et_16_concat'],
                       [['log_PropertyGFATotal', 'log_PropertyGFAParking', 'NumberofBuildings', 'Anciennete', 'log_measure_floors'], 'log_SiteEnergyUse(kBtu)', 'df_15_et_16_concat'],
                      [['log_PropertyGFATotal', 'log_PropertyGFAParking', 'log_PropertyGFABuilding(s)', 'NumberofBuildings', 'Anciennete'], 'log_SiteEnergyUse(kBtu)', 'df_15_et_16_concat'],
                      [['log_PropertyGFATotal', 'log_PropertyGFAParking', 'NumberofBuildings', 'Anciennete', 'log_measure_floors'], 'log_SiteEnergyUse(kBtu)', 'df_15_et_16_concat']]

modeles_lineaires13 = [[['PropertyGFATotal', 'Anciennete', 'measure_floors'], 'TotalGHGEmissions', 'df_15_et_16_concat'],
                      [['PropertyGFATotal', 'PropertyGFABuilding(s)', 'Anciennete'], 'TotalGHGEmissions', 'df_15_et_16_concat'],
                      [['PropertyGFATotal', 'Anciennete', 'measure_floors'], 'TotalGHGEmissions', 'df_15_et_16_concat']]

modeles_lineaires14 = [[['log_PropertyGFATotal', 'Anciennete', 'log_measure_floors'], 'log_TotalGHGEmissions', 'df_15_et_16_concat'],
                      [['log_PropertyGFATotal', 'log_PropertyGFABuilding(s)', 'Anciennete'], 'log_TotalGHGEmissions', 'df_15_et_16_concat'],
                      [['log_PropertyGFATotal', 'Anciennete', 'log_measure_floors'], 'log_TotalGHGEmissions', 'df_15_et_16_concat']]

modeles_lineaires15 = [[['log_PropertyGFATotal', 'Anciennete', 'log_measure_floors'], 'SiteEnergyUse(kBtu)', 'df_15_et_16_concat'],
                      [['log_PropertyGFATotal', 'log_PropertyGFABuilding(s)', 'Anciennete'], 'SiteEnergyUse(kBtu)', 'df_15_et_16_concat'],
                      [['log_PropertyGFATotal', 'Anciennete', 'log_measure_floors'], 'SiteEnergyUse(kBtu)', 'df_15_et_16_concat']]

modeles_lineaires16 = [[['log_PropertyGFATotal', 'Anciennete', 'log_measure_floors'], 'log_SiteEnergyUse(kBtu)', 'df_15_et_16_concat'],
                      [['log_PropertyGFATotal', 'log_PropertyGFABuilding(s)', 'Anciennete'], 'log_SiteEnergyUse(kBtu)', 'df_15_et_16_concat'],
                      [['log_PropertyGFATotal', 'Anciennete', 'log_measure_floors'], 'log_SiteEnergyUse(kBtu)', 'df_15_et_16_concat']]

modeles_lineaires17 = [[['log_PropertyGFATotal', 'log_PropertyGFAParking', 'NumberofBuildings', 'Anciennete', 'log_measure_floors'], 'TotalGHGEmissions', 'df_15_et_16_concat'], 
                        [['log_PropertyGFATotal', 'Anciennete', 'log_measure_floors'], 'TotalGHGEmissions', 'df_15_et_16_concat']]

modeles_lineaires18 = [[['log_PropertyGFATotal', 'Anciennete', 'log_measure_floors', 'ENERGYSTARScore'], 'log_SiteEnergyUse(kBtu)', 'df_15_et_16_concat_star'], 
                        [['log_PropertyGFATotal', 'Anciennete', 'log_measure_floors', 'ENERGYSTARScore'], 'log_TotalGHGEmissions', 'df_15_et_16_concat_star']]
                        
modeles_lineaires19 = [[['log_PropertyGFATotal', 'Anciennete', 'log_measure_floors'], 'log_SiteEnergyUse(kBtu)', 'df_15_et_16_concat'],
                        [['log_PropertyGFATotal', 'Anciennete', 'log_measure_floors'], 'log_TotalGHGEmissions', 'df_15_et_16_concat']]

list_to_log = ['PropertyGFATotal', 'PropertyGFAParking', 'PropertyGFABuilding(s)', 'SiteEnergyUse(kBtu)', 'SiteEnergyUseWN(kBtu)', 'SiteEUI(kBtu_over_sf)', 'SiteEUIWN(kBtu_over_sf)', 'TotalGHGEmissions', 'GHGEmissionsIntensity', 'measure_floors', 'Anciennete']

# Fonction de création et de normalisation des matrices du modèle
def create_X_and_scale(l_colnames, f):
    df = l_colnames[2] # nom du dataframe à utiliser
    lista_nomi_colonne_per_matrice_X = l_colnames[0]

    for i in l_l_instances:
            if df == i[0]: # 1. Si le nom du df coincide...
                l_instances_a_utiliser = i[1] # on a identifié la bonne liste des instances
                l_tmp = l_instances_a_utiliser[0].df.shape[0]
                l_ind_x_previsto=len(l_colnames[0])
                break
            else:
              print('not found')

    tmp = np.empty(l_tmp, dtype=object).reshape(l_tmp, 1)
    # print(tmp[:5])
    inst_x = []
    l_ind_x_incr = 0

    for i in l_instances_a_utiliser: #2. Dentro la lista delle istanze ...
        num_cols_X = len(lista_nomi_colonne_per_matrice_X)
        for j in range(num_cols_X):  #... per ciascuna colonna da trovare
            if lista_nomi_colonne_per_matrice_X[j] == i.name: # se il nome della colonna dentro la lista delle istanze coincide...
                print(j, lista_nomi_colonne_per_matrice_X[j])
                l_ind_x_incr+=1
                inst_x.append(i)
                print(i)
                print(i.name)

                x = i.df[i.name].to_numpy(dtype=np.float32)
                x = x.reshape(x.shape[0], 1)
                if l_ind_x_incr!=1:
                    print("ind %i" % l_ind_x_incr)
                    print("tmp.shape prima: %s" % str(tmp.shape))
                    tmp = np.hstack([tmp, x])
                    print("tmp.shape dopo: %s" % str(tmp.shape))
                    # print(tmp[:5])
                else:
                    print("TMP tmp.shape prima: %s" % str(tmp.shape))
                    tmp = x
                    print("tmp.shape dopo: %s" % str(tmp.shape))
                    # print(tmp[:5])
                    # print(tmp[:5][:5])
    X = tmp
    print("X.shape: %s" % str(X.shape))

    if len(inst_x)!=num_cols_X:
        print("%i != %i" % (len(inst_x), num_cols_X))
        return

    #SCALER
    scaler = preprocessing.StandardScaler().fit(X)
    X_scaled = scaler.transform(X)
    for j in range(num_cols_X):
        f.write("#new mean col %i : %f (%.3f), %s\n" % (j, X_scaled[j].mean(axis=0), X_scaled[j].mean(axis=0), X_scaled[j].mean(axis=0).dtype))
        f.write("#new std col %i:  %f, %s\n" % (j, X_scaled[j].std(axis=0), X_scaled[j].std(axis=0).dtype))

    for i in l_instances_a_utiliser:
        if l_colnames[1]==i.name:
            inst_y = i
            y = i.df[i.name].to_numpy()
            break

    return X_scaled, y, inst_x, inst_y

# Comparaison des Algorithmes


# Définition d'une fonction de test de performance d'un modèle
def test_model(X_train, X_test, y_train, y_test, model):
    predictions_test = model.predict(X_test)
    predictions_train = model.predict(X_train)

    rmse_test = mean_squared_error(y_test, predictions_test, squared=False)
    r2_test = r2_score(y_test, predictions_test)
    
    rmse_train = mean_squared_error(y_train, predictions_train, squared=False)
    r2_train = r2_score(y_train, predictions_train)
    
    return (rmse_test, r2_test, rmse_train, r2_train)

# Configuration
seed = 7
n_rounds_train = 15
n_rounds_fit = 3
num_splits_cv = 5

alphas = np.logspace(-6, 6, 25).tolist()# l1_range = np.linspace(0, 1, 11).tolist()
l1_range = np.linspace(0.05, 0.95, 4).tolist()
n_estimators = (10, 20, 30, 40) # ... 90
depths = (10, 20, 30, 40)

models = []
models.append(('Dummy ', DummyRegressor(), {}))
models.append(('Linear   ', LinearRegression(), {}))
models.append(('Ridge ', Ridge(), {'alpha': alphas, 'max_iter': [1000000]} ))
models.append(('Lasso ', Lasso(),  {'alpha': alphas, 'max_iter': [1000000]} ))
models.append(('Elastic Net', ElasticNet(),  {'l1_ratio': l1_range, 'max_iter': [10000000]} ))
models.append(('RF    ', RandomForestRegressor(), {'max_depth' : depths })) #https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html?highlight=randomforest#sklearn.ensemble.RandomForestRegressor

now = str(datetime.datetime.now())
print(now)
print(models)
rmse = make_scorer(mean_squared_error, squared=False, greater_is_better=False)
r2 = make_scorer(r2_score)

#Fichiers à écrire (fianlement moins utiles que out.log)
#*********************************************************************
filenamef = "log_comparaison_algorithmes2.txt"
f = open(filenamef, 'w')

f.write("#*********************************************************************\n%s\n" % now)

filenameg = "log_comparaison_algorithmes_donnees_seulement2.txt"
g = open(filenameg, 'w')
g.write("#*********************************************************************\n%s\n" % now)

filenamel = "log_comparaison_algorithmes2.tex"
l = open(filenamel, 'w')
l.write("\\documentclass[]{article}\n\\usepackage{amssymb,latexsym,amsmath,float}\n\\usepackage[landscape]{geometry}\n\\floatplacement{figure}{H}\n\\begin{document}\n")

n=0


# Création et évaluation des modèles
for i in (modeles_lineaires18, modeles_lineaires19) :
    for j in i:
        # if n>1:
        #     break

        strj = str(j)
        print(strj)
        f.write("%s\n------------------\n" % strj)
        g.write("%s\n------------------\n" % strj)

        strj_tex = strj.replace('_',' ')
        l.write("Modèle %s\n\n" % strj_tex)

        X, y, inst_x, inst_y = create_X_and_scale(j, f)

        # evaluate each model in turn
        results = []
        ci = []
        names = []
        # scoring = 'r2'
        perf_all_methods = []

        f.write("Model %i [Keynote %i]\n" % (n, n+1))
        g.write("Model %i [Keynote %i]\n" % (n, n+1))
        # g.write("name, t_exec, cv_results.mean(), cv_results.std(), r2_train.mean(), r2_train.std(), r2_test.mean(), r2_test.std()\n")

        # l.write("Model %i (Keynote model n. %i)\\\\\\begin{table}[]\n\\centering\n\\begin{tabular}{|l|l|l|l|l|l|}\n\\hline\n" % (n, n+1))
        # l.write("name & t_exec & cv_results.mean() & cv_results.std() & r2_train.mean() & r2_train.std() & r2_test.mean() & r2_test.std()\\\\\n")

        f.write("num_rounds train: %i\nnum_rounds train: %i\n" % (n_rounds_train, n_rounds_fit))

        f.write("Model %i [Keynote %i]\n" % (n, n + 1))
        g.write("Model %i [Keynote %i]\n" % (n, n + 1))

        kf = KFold(n_splits=num_splits_cv, random_state=seed, shuffle=True) #https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score

        for name, model, parameters in models:

            strp_tex = str(parameters).replace('_',' ')

            for round_fit in range(0, n_rounds_fit):
                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)  # https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split  # if name in ('RF    '):

                alpha_rmse_train_l = np.arange(0)
                alpha_r2_train_l = np.arange(0)

                odg_1_l = np.arange(0)
                odg_2_l = np.arange(0)

                w_odg_1_l = np.arange(0)
                w_odg_2_l = np.arange(0)
                l.write("Estimateur %s %s %s\n\\vspace{0.5cm}" % (name, model, strp_tex))
                print("Estimateur %s %s %s\n" % (name, model, strp_tex))

                l.write("Fit round %i\n\\vspace{0.5cm}" % (round_fit))

                rmse_test = np.arange(0)
                rmse_test_std = np.arange(0)
                r2_test = np.arange(0)
                r2_test_std = np.arange(0)
                rmse_train = np.arange(0)
                rmse_train_std = np.arange(0)
                r2_train = np.arange(0)
                r2_train_std = np.arange(0)
                t_exec = np.arange(0)

                for r_train in range(0, n_rounds_train):
                    X_train_round, X_test_round, y_train_round, y_test_round = train_test_split(X_train, y_train, test_size=0.2)  # https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split

                    t_exec_l = np.arange(0)
                    rmse_test_l = np.arange(0)
                    r2_test_l = np.arange(0)
                    rmse_train_l = np.arange(0)
                    r2_train_l = np.arange(0)

                    start = datetime.datetime.now()

#Table on X_train_round without hyperparameters
                    if not parameters.keys():

                        if name == 'Dummy ':
                            model_for_train_test = DummyRegressor()

                        if name == 'Linear   ':
                            model_for_train_test = LinearRegression()

                    elif parameters.keys():

                        grid_search = 0
                        grid_search2 = 0

                        model3 = clone(model, safe=True)

                        final_alpha = 0
                        best_alpha_rmse_1 = 0
                        best_alpha_r2_1 = 0

                        model1 = clone(model, safe=True)
                        model2 = clone(model, safe=True)

                        print("parameters", parameters)
                        # grid_search = GridSearchCV(model1, param_grid = parameters, scoring=rmse, verbose=4, cv=kf)
                        grid_search = GridSearchCV(model1, param_grid = parameters, scoring=rmse, verbose=1, cv=kf)
                        grid_search.fit(X_train_round, y_train_round)
                        test_rmse_1 = test_model(X_train_round, X_test_round, y_train_round, y_test_round, grid_search)
                        print("%s: test_rmse_1: %s" % (name, str(test_rmse_1)))
                        best_parameters_rmse_1 = grid_search.best_estimator_.get_params()
                        print("best_parameters_rmse_1: %s" % best_parameters_rmse_1)

                        # grid_search2 = clone(grid_search, safe=True)  # https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone
                        # grid_search2 = GridSearchCV(model2, param_grid = parameters, scoring=r2, verbose=4, cv=kf)
                        grid_search2 = GridSearchCV(model2, param_grid = parameters, scoring=r2, verbose=1, cv=kf)
                        grid_search2.fit(X_train_round, y_train_round)
                        test_r2_1 = test_model(X_train_round, X_test_round, y_train_round, y_test_round, grid_search2)
                        print("%s: test_r2_1: %s" % (name, str(test_r2_1)))
                        best_parameters_r2_1 = grid_search2.best_estimator_.get_params()
                        print("best_parameters_r2_1: %s" % best_parameters_r2_1)

                        if name in ('Ridge ', 'Lasso '):
                            nhp='alpha'
                        elif name in ('Elastic Net'):
                            nhp='l1_ratio'
                        elif name == 'RF    ':
                            nhp = 'max_depth'

                            best_alpha_rmse_1 = best_parameters_rmse_1[nhp]
                            best_alpha_r2_1 = best_parameters_r2_1[nhp]

                            alpha_rmse_train_l = np.append(alpha_rmse_train_l, best_alpha_rmse_1)
                            alpha_r2_train_l = np.append(alpha_r2_train_l, best_alpha_r2_1)

                            print('Best nhp rmse_1: %0f from list %s' % (best_alpha_rmse_1, str(parameters)))
                            print('Best score rmse_1: %f' % grid_search.best_score_)
                            print('Best parameters set rmse_1: %s' % best_parameters_rmse_1)

                            print('Best nhp r2_1: %0f from list %s' % (best_alpha_r2_1, str(parameters)))
                            print('Best score r2_1: %f' % grid_search2.best_score_)
                            print('Best parameters set r2_1: %s' % best_parameters_r2_1)

                            print("END alpha_rmse_train_l" , alpha_rmse_train_l)
                            print("END alpha_r2_train_l" , alpha_r2_train_l)

                            odg1 = math.floor(math.log10(best_alpha_rmse_1))
                            odg2 = math.floor(math.log10(best_alpha_r2_1))

                            odg_1_l = np.append(odg_1_l, odg1)
                            odg_2_l = np.append(odg_2_l, odg2)
                            if r_train == 0:
                                l.write("Model %i (Keynote model n. %i) - round %i\n" % (n, n + 1, round_fit))
                                l.write("\\begin{table}[]\n\\centering\n\\begin{tabular}{|l|l|l|l|l|l|}\n\\hline\n" )
                                l.write("round fit & round training & name & runtime & best alpha GS (rmse) & best alpha GS (r2)\\\\ \\hline\n" )
                            l.write("%i & %i & %s & %f & %f & %f \\\\ \\hline\n" % ( round_fit, r_train, name, t_exec_i, alpha_rmse_train_l[-1], alpha_r2_train_l[-1]))

                            if r_train == n_rounds_train-1:
                                l.write("\\end{tabular}\n\\end{table}\\\\ \\clearpage\n")
#
                                to_average = np.append(np.average(alpha_rmse_train_l), np.average(alpha_r2_train_l))
                                final_alpha = np.average(to_average)

                                #Statistiques sur les ordres de grandeur des hypeparamètres
                                odg_1_recurrent = stats.mode(odg_1_l)
                                odg_1_min = np.amin(odg_1_l)
                                odg_1_max = np.amax(odg_1_l)
                                odg_1_hist, odg_1_bins = np.histogram(odg_1_l, bins=[-6,-5,-4,-3,-2,-1,0,1,2,3,4,5,6])

                                odg_2_recurrent = stats.mode(odg_2_l)
                                odg_2_min = np.amin(odg_2_l)
                                odg_2_max = np.amax(odg_2_l)
                                odg_2_hist, odg_2_bins = np.histogram(odg_2_l, bins=[-6,-5,-4,-3,-2,-1,0,1,2,3,4,5,6])

                                print("END odg1", odg_1_recurrent, odg_1_hist)
                                print("END odg2", odg_2_recurrent, odg_2_hist)

                                #assigne estimateur

                                if name == 'Ridge ':
                                    model_for_train_test = Ridge(alpha=final_alpha)

                                elif name == 'Lasso ':
                                    model_for_train_test = Lasso(alpha=final_alpha)

                                elif name in 'Elastic Net':
                                    model_for_train_test = ElasticNet(l1_ratio=final_alpha)

                                elif name == 'RF    ':
                                    model_for_train_test = RandomForestRegressor(max_depth=final_alpha)

#FIT sur X_train

                    model_for_train_test.fit(X_train_round, y_train_round)
                    end = datetime.datetime.now()
                    t_exec_i = (end - start).total_seconds()
                    t_exec_l = np.append(t_exec_l, t_exec_i)

                    performance = test_model(X_train, X_test, y_train, y_test, model_for_train_test)

                    rmse_test_l = np.append(rmse_test_l, performance[0])
                    r2_test_l = np.append(r2_test_l, performance[1])
                    rmse_train_l = np.append(rmse_train_l, performance[2])
                    r2_train_l = np.append(r2_train_l, performance[3])

                    if round_fit == 0:
                        l.write("Model %s - %i (Keynote model n. %i) - Fit on X train N. %i\n\\begin{table}[]\n\\centering\n\\begin{tabular}{|l|l|l|l|l|l|l|l|l|}\n\\hline\n" % (name, n, n + 1, round_fit))
                        l.write("round fit & round training & name & runtime & hyperparameter & rmse test & r2 test & rmse train & r2 train \\\\ \\hline\n" )

                    if name in ('Dummy ', 'Linear   '):
                        l.write("%i & %i & %s & %f & X & %f & %f & %f & %f \\\\ \\hline\n" % (round_fit, r_train, name, t_exec_i, performance[0], performance[1], performance[2], performance[3]))
                    # l.write("%i & %i & %s & %f & X & %f & %f & %f & %f \\\\ \\hline\n" % (round_fit, r_train, name, t_exec_i, rmse_test_l[-1], r2_test_l[-1], rmse_train_l[-1], r2_train_l[-1]))
                    elif name in ('Ridge ', 'Lasso ', 'Elastic Net', 'RF    '):
                        l.write("%i & %i & %s & %f & %f & %f & %f & %f & %f  \\\\ \\hline\n" % (round_fit, r_train, name, t_exec_i, final_alpha, performance[0], performance[1], performance[2], performance[3]))

                    if (round_fit == n_rounds_fit-1) and ( r_train == n_rounds_train-1 ):
                        l_app = (n, name, t_exec_l.mean(), rmse_test_l.mean(), rmse_test_l.std(), r2_test_l.mean(), r2_test_l.std(), rmse_train_l.mean(), rmse_train_l.std(), r2_train_l.mean(), r2_train_l.std())
                        perf_all_methods.append(l_app)
                        l.write("\\end{tabular}\n\\end{table}\n\\clearpage\n")

            print("###", n, strj_tex, perf_all_methods)
            n+=1
           
l.write("\\end{document}\n")
f.close()
g.close()
l.close()

os.system("cat %s " % filenamef)
os.system('cat %s >> all_%s' % (filenamef, filenamef))
print('pdflatex %s ; open log_comparaison_algorithmes2.pdf' % (filenamel))


